#!/usr/bin/perl

########################################################
#
# This is the configuration file for the srna-
# tools application.
# This file configures the application itself. There
# is another config file called tools.conf, which
# configures tool-specific behaviour.
# 
# The format is normal Perl code that is interpreted by
# the ConifgAuto module in the SrnaTools::Config class.
#
########################################################

use strict;
use File::Basename;
use FindBin '$Bin';

my $srna_path=dirname($Bin);

my %cnf=(
  
  # These are the tools that we make available on this site
  # Use short lowercase names here that can also be used to
  # pass between scripts on the website etc. A display name
  # and description can be defined in the tools section
  tools => [
    'mircat',
    'siloco',
    'phasing',
    'adaptor',
    'mirprof',
    'filter',
    'siloma',
    'hp_tool',
    'target',
    'firepat',
  ] ,
  
  # Set debug to 1 to print full error
  # messages including script names and line numbers
  # in the browser. Set this to 0 for live web sites.
  # In both cases, full error messages are printed to 
  # the server's error-log in addition.
  debug => 1,
  # if no_job_submission is used, jobs are created
  # and (batch jobs) sent to queue dir but are not
  # submitted to queue. This can be useful for 
  # debugging purposes
  #no_job_submission => 1,
  
  # uncomment this option to keep the job's working directory
  # on cluster on in local batch queue after a job has finished.
  # Default is to delete it but it may be useful for debugging
  # to see all intermediate files that were created.
  # Set to zero or comment out on production server
  #dont_delete_job_working_dir => 1,

  ################################################
  # Paths to directories on server and cluster
  # where we put jobs into the queue, store
  # genome data and third-party binaries.
  # All paths are relative to the "doc root"
  # i.e. the srna-tools directory
  ################################################
  
  # path to srna-tools "root directory" on the 
  # cluster backend and the server. The server root
  # could be determined dynamically at run time but
  # with this set up we can share resources between
  # web apps by pointing them to the same root dir.
  # It also creates a more unified interface to path data
  root_dir => {
  	#server => '/local/scratch/martin/srna-tools-cli-minimal/',
  	#server => $srna_path,
  	server => '/PROJECT/Pipeline/sRNA_v2.3/BioSoft/srna-tools-cli',
  },
  
  # this is where jobs are send to get queued,
  # not the job storage area on the server
  # (job_dir_server). 
  # We give a value for environmet "server" 
  # just for instant jobs where storage = 
  # execution dir.
  queue_job_dir => {
    server => '/jobs/',
  },
  
  # Dir for uploaded and finished jobs (not queued ones)
  # This is where jobs get created and where we copy the
  # results to after they have been completed. We only 
  # have this on the server.
  job_storage_dir => {
    server =>  '/jobs/'
  }, 

  # path to backend scripts
  lib_dir => {
    server  => '/lib/',
  },
  
  # additional search paths for Perl
  # modules in different environments
  module_dir => { },
  
  # additional third party binaries - TODO: no longer required: delete
  bin_dir => {
    server  => '/lib/bin/',
  },

  # public data, such as genomes
  data_dir => {
    server  => '/data/', 
  },

  log_file => { 
    server  => '/log/batch_jobs.log',
  },

  # These are the user-name@host-name strings
  # that we need in order to ssh to remote machines.
  # 'cluster' will be used on the server to send
  # data to the cluster and 'server' is only
  # needed on the cluster to send data back.
  user_host_name => { 
    server => 'apache@fschwachpc2.cmp.uea.ac.uk'
  },
  
  # total disk usage allowance in byte (job queue directories)
  # stop accepting jobs if this maximum has been reached.
  usage_allowance => {
    server  => 20e9,
  },
  
  # for automatic mirbase updates
  mirbase_download_url => "ftp://mirbase.org/pub/mirbase/CURRENT/",
  
########################################################
# web section
# Configuration in this section is specific to web 
# implementations of the tools
########################################################

  # Header and page title text
  title => 'plant version',
  
  # Some common html partials, such as the index,
  # about, publications and the sidenav, which is
  # included in the layout.
  home_page_partial => 'start.tt',
  sidenav_partial => 'sidenav.tt',

  # set maximum amount of POST data to X *1000
  # where X is in MB
  post_max => 200 * 1e6,
  
  # do not accept more jobs for remote (cluster)
  # queue if this is exceeded. A warning message is
  # sent to the admins and an error is displayed to the user
  max_number_jobs_queue => 100,

  # This is the email address we send 
  # confimration emails from
  email_from => 'no-reply-srna-tools@cmp.uea.ac.uk',
  
  # Admin email address
  admin_email => 'srna-tools@cmp.uea.ac.uk',

  # The path and filename to the downtime
  # schedule file
  downtime_schedule_file =>  '/config/downtime_schedule.txt',

  # This is where the html templates (html partials) live
  html_template_path => 'html_templates/',
  
  # Templaes for emails
  email_template_path => 'email_templates/',
  
  ########################################################
  # Command Line Interface section
  ########################################################
  cli_template_path => 'cli_templates/',
  
) ;



# DO NOT DELETE THIS
\%cnf ;
